{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7239d0-09ed-4db2-ae82-3349cffbe1fc",
   "metadata": {},
   "source": [
    "# **ASSIGNMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ef413-e4cf-4745-b209-25ecce08c218",
   "metadata": {},
   "source": [
    "**Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dff8e4-238b-458f-ba05-9b2da810707c",
   "metadata": {},
   "source": [
    "Polynomial functions and kernel functions are both mathematical tools used in machine learning, particularly in the context of support vector machines (SVMs) and kernel methods. Here's a brief overview of their relationship:\n",
    "\n",
    "1. **Polynomial Functions:**\n",
    "   - In the context of SVMs, polynomial functions are often used as basis functions to transform input data into a higher-dimensional space.\n",
    "   - The idea is to map the input data from its original space to a higher-dimensional space, where a hyperplane can better separate the data points.\n",
    "   - The polynomial kernel function is a specific type of kernel function used in SVMs that employs polynomial functions.\n",
    "\n",
    "2. **Kernel Functions:**\n",
    "   - In machine learning, a kernel function is a method of implicitly mapping input data into a higher-dimensional space without explicitly computing the new representation.\n",
    "   - Kernels play a crucial role in kernelized algorithms, such as kernelized SVMs. They allow these algorithms to operate in a higher-dimensional space without explicitly computing the transformation.\n",
    "   - Polynomial kernels are a type of kernel function commonly used. The polynomial kernel function \\(K(x, y) = (x \\cdot y + c)^d\\) is based on polynomial functions, where \\(d\\) is the degree of the polynomial, and \\(c\\) is a constant.\n",
    "\n",
    "3. **Relationship:**\n",
    "   - Polynomial functions are a type of basis function used in the construction of polynomial kernel functions.\n",
    "   - The polynomial kernel function is a specific form of a kernel function that relies on the polynomial transformation of input data.\n",
    "   - Other types of kernel functions include linear kernels, radial basis function (RBF) kernels, and more. Each type of kernel function corresponds to a different way of transforming the input data.\n",
    "\n",
    "In summary, polynomial functions are often used as the basis for polynomial kernel functions in machine learning algorithms like SVMs. The kernel functions, including polynomial kernels, enable the algorithms to operate in higher-dimensional spaces efficiently, allowing for better decision boundaries and improved performance on complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33802375-700b-447c-ab98-0b9055c5cbe6",
   "metadata": {},
   "source": [
    "**Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451531e4-c511-47c5-83f9-4fca09aad953",
   "metadata": {},
   "source": [
    "Implementing an SVM with a polynomial kernel in Python using Scikit-learn is relatively straightforward. Scikit-learn provides the `SVC` (Support Vector Classification) class, which allows you to create an SVM model with different kernel functions, including the polynomial kernel.\n",
    "\n",
    "Here's a simple example of implementing an SVM with a polynomial kernel using Scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a sample dataset (you can replace this with your own dataset)\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM model with a polynomial kernel\n",
    "degree_of_polynomial = 3  # Set the degree of the polynomial kernel\n",
    "svm_model = SVC(kernel='poly', degree=degree_of_polynomial)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "1. We load the Iris dataset as a sample dataset.\n",
    "2. Split the dataset into training and testing sets.\n",
    "3. Create an `SVC` model with a polynomial kernel using the `kernel='poly'` parameter. The `degree` parameter specifies the degree of the polynomial.\n",
    "4. Train the model using the training data.\n",
    "5. Make predictions on the test set.\n",
    "6. Evaluate the accuracy of the model using the `accuracy_score` function from Scikit-learn's `metrics` module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca740c9-8671-4999-958b-1c99ae34881f",
   "metadata": {},
   "source": [
    "**Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d827c6-c78b-4ce0-a632-a6f48d7c78a4",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), epsilon (often denoted as ε) is a hyperparameter that controls the width of the margin around the predicted values within which no penalty is associated with errors. It is part of the formulation of the loss function in SVR, and it introduces a tolerance for errors that fall within the margin.\n",
    "\n",
    "The SVR optimization problem aims to find a function that fits the training data while allowing for a certain amount of error. The margin of tolerance is defined by the epsilon-insensitive loss function, which ignores errors smaller than epsilon. The SVR loss function is typically defined as:\n",
    "\n",
    "\\[ L(y, f(x)) = \\max(0, |y - f(x)| - \\epsilon) \\]\n",
    "\n",
    "Here:\n",
    "- \\(y\\) is the true output,\n",
    "- \\(f(x)\\) is the predicted output,\n",
    "- \\(|y - f(x)|\\) is the absolute difference between the true and predicted outputs,\n",
    "- \\(\\epsilon\\) is the epsilon parameter.\n",
    "\n",
    "Now, let's discuss the impact of increasing the value of epsilon on the number of support vectors:\n",
    "\n",
    "1. **Smaller Epsilon (Tight Margin):**\n",
    "   - Smaller values of epsilon result in a tighter margin around the predicted values.\n",
    "   - With a tight margin, the SVR model becomes sensitive to small errors, and more data points may become support vectors.\n",
    "\n",
    "2. **Larger Epsilon (Wider Margin):**\n",
    "   - Larger values of epsilon lead to a wider margin, allowing for larger errors without incurring a penalty.\n",
    "   - A wider margin means that fewer data points are treated as support vectors, as the model becomes more tolerant of errors within the margin.\n",
    "\n",
    "In summary, increasing the value of epsilon in SVR tends to decrease the number of support vectors because a larger epsilon allows for a wider margin of tolerance for errors. The model becomes less sensitive to small deviations, and data points that fall within the wider margin are not treated as support vectors. The choice of epsilon should be made carefully based on the problem at hand and the desired balance between fitting the training data and generalizing to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea6291-73e5-4e14-8ead-1422eb2d691c",
   "metadata": {},
   "source": [
    "**Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002955dc-3e99-42e2-91e2-90bbe0254e01",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR) is a machine learning algorithm that uses support vector machines for regression tasks. The performance of SVR is influenced by several hyperparameters, including the choice of kernel function, the C parameter, the epsilon parameter (ε), and the gamma parameter (γ). Let's discuss each parameter and how it affects the SVR performance:\n",
    "\n",
    "1. **Kernel Function:**\n",
    "   - **Description:** The kernel function determines the type of mapping used to transform the input features into a higher-dimensional space. Common choices include linear, polynomial, and radial basis function (RBF) kernels.\n",
    "   - **Effect on Performance:** The choice of the kernel depends on the nature of the data. RBF kernels are often versatile and work well in various scenarios. Linear kernels are suitable for linear relationships, while polynomial kernels are useful for capturing non-linear relationships.\n",
    "   - **Example:** If you suspect that the relationship between input and output is non-linear, you might choose an RBF kernel (`kernel='rbf'`). Experiment with different kernels to see which performs best on your specific dataset.\n",
    "\n",
    "2. **C Parameter:**\n",
    "   - **Description:** The C parameter controls the trade-off between achieving a low training error and a smooth decision surface. A smaller C encourages a smoother decision surface, while a larger C allows the model to fit the training data more closely.\n",
    "   - **Effect on Performance:** Larger values of C can lead to overfitting, especially if the data has noise. Smaller values of C promote a simpler model but may result in underfitting.\n",
    "   - **Example:** If your training data has outliers or noise, you may want to decrease C (`C=0.1` or `C=1`) to prevent the model from fitting the noise too closely.\n",
    "\n",
    "3. **Epsilon Parameter (ε):**\n",
    "   - **Description:** Epsilon defines the margin of tolerance for errors within which no penalty is associated with the training data. It is part of the epsilon-insensitive loss function.\n",
    "   - **Effect on Performance:** Smaller epsilon values make the model more sensitive to errors, potentially resulting in more support vectors. Larger epsilon values increase the margin and make the model more tolerant of errors.\n",
    "   - **Example:** If you want the model to be less sensitive to small errors in the training data, you might increase epsilon (`epsilon=0.1` or `epsilon=0.2`).\n",
    "\n",
    "4. **Gamma Parameter (γ):**\n",
    "   - **Description:** The gamma parameter defines the influence of a single training example, with low values meaning far influence and high values meaning close influence. It is specific to RBF kernels.\n",
    "   - **Effect on Performance:** Smaller gamma values result in a smoother decision boundary, while larger gamma values lead to a more complex decision boundary, potentially causing overfitting.\n",
    "   - **Example:** If you observe overfitting with an RBF kernel, you might try decreasing gamma (`gamma=0.1` or `gamma=0.01`) to make the decision boundary smoother.\n",
    "\n",
    "In summary, the choice of kernel function, C parameter, epsilon parameter, and gamma parameter in SVR depends on the characteristics of your data. It often involves a trade-off between fitting the training data well and generalizing to new data. Experimentation and tuning these parameters using techniques like cross-validation are crucial for achieving optimal SVR performance on a specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeda605-d16a-4647-bba5-71f718d03d59",
   "metadata": {},
   "source": [
    "**Q5. Assignment:**<br>\n",
    "\n",
    ". Import the necessary libraries and load the dataset<br>\n",
    ". Split the dataset into training and testing sets<br>\n",
    ". Preprocess the data using any technique of your choice (e.g. scaling, normaliMation)<br>\n",
    ". Create an instance of the SVC classifier and train it on the training data<br>\n",
    ". Use the trained classifier to predict the labels of the testing data<br>\n",
    ". Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-score)<br>\n",
    ". Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performance<br>\n",
    ". Train the tuned classifier on the entire dataset<br>\n",
    ". Save the trained classifier to a file for future use.<br>\n",
    "\n",
    "**Note: You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576e6570-a769-4ab3-ab9a-718ec6ea0b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Best Hyperparameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tuned_svc_classifier.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data - Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict labels on the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Evaluate the performance using classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_classifier = SVC(**best_params)\n",
    "tuned_classifier.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file using joblib\n",
    "joblib.dump(tuned_classifier, 'tuned_svc_classifier.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47d09b-9909-4d58-aaec-7235818e5dd7",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13ed21-4791-427e-83b8-9b0f09b3c2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
